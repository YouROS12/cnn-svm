{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Margin-Aware Contrastive Learning with SVM for Plant Disease Detection\n",
    "\n",
    "## Paper Implementation: Contrastive Learning + SVM Classification\n",
    "\n",
    "This notebook implements a novel approach combining:\n",
    "- **SimCLR-style contrastive pretraining** for learning robust representations\n",
    "- **SVM classification head** leveraging maximum margin properties\n",
    "- **Application to PlantWildV2** dataset for plant disease detection\n",
    "\n",
    "### Key Innovation\n",
    "We hypothesize that SVM's maximum margin principle naturally aligns with contrastive learning's objective of separating representations in embedding space, leading to:\n",
    "- Better few-shot learning performance\n",
    "- Improved robustness to domain shift\n",
    "- Enhanced feature separability\n",
    "\n",
    "### Author: [Your Name]\n",
    "### Date: 2025-10-31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (for Colab)\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q scikit-learn matplotlib seaborn\n",
    "!pip install -q tensorboard pillow tqdm\n",
    "!pip install -q thundersvm  # GPU-accelerated SVM (optional, falls back to sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration for the entire pipeline\"\"\"\n",
    "    \n",
    "    # Data paths\n",
    "    DATA_ROOT = './plantwildV2'  # Change this to your dataset path\n",
    "    CHECKPOINT_DIR = './checkpoints'\n",
    "    RESULTS_DIR = './results'\n",
    "    \n",
    "    # Image parameters\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_WORKERS = 4\n",
    "    \n",
    "    # Contrastive learning parameters\n",
    "    PROJECTION_DIM = 128  # Dimension of projection head output\n",
    "    EMBEDDING_DIM = 512   # Dimension of encoder output\n",
    "    TEMPERATURE = 0.5     # Temperature for NT-Xent loss\n",
    "    \n",
    "    # Training parameters - Contrastive\n",
    "    CONTRASTIVE_EPOCHS = 200\n",
    "    CONTRASTIVE_LR = 3e-4\n",
    "    CONTRASTIVE_WEIGHT_DECAY = 1e-6\n",
    "    \n",
    "    # Training parameters - SVM\n",
    "    SVM_C = 1.0  # SVM penalty parameter\n",
    "    SVM_KERNEL = 'linear'  # 'linear' or 'rbf'\n",
    "    SVM_MAX_ITER = 1000\n",
    "    \n",
    "    # Fine-tuning parameters\n",
    "    FINETUNE_EPOCHS = 50\n",
    "    FINETUNE_LR = 1e-4\n",
    "    FINETUNE_WEIGHT_DECAY = 1e-5\n",
    "    \n",
    "    # Augmentation parameters\n",
    "    COLOR_JITTER_STRENGTH = 0.5\n",
    "    GAUSSIAN_BLUR_KERNEL = 23\n",
    "    \n",
    "    # Experiment settings\n",
    "    ENABLE_FEW_SHOT = True\n",
    "    FEW_SHOT_K = [1, 5, 10, 20]  # K-shot learning scenarios\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(config.RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveAugmentation:\n",
    "    \"\"\"Strong augmentation for contrastive learning (SimCLR style)\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=224, strength=0.5):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(img_size, scale=(0.2, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply([\n",
    "                transforms.ColorJitter(0.8*strength, 0.8*strength, 0.8*strength, 0.2*strength)\n",
    "            ], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.RandomApply([transforms.GaussianBlur(23, sigma=(0.1, 2.0))], p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # Return two augmented views of the same image\n",
    "        return self.transform(x), self.transform(x)\n",
    "\n",
    "\n",
    "class StandardAugmentation:\n",
    "    \"\"\"Standard augmentation for supervised training\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=224, is_train=True):\n",
    "        if is_train:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(img_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomRotation(15),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(img_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.transform(x)\n",
    "\n",
    "\n",
    "class PlantWildV2Dataset(Dataset):\n",
    "    \"\"\"Custom dataset loader for PlantWildV2\n",
    "    \n",
    "    Expected structure:\n",
    "    plantwildV2/\n",
    "        class1/\n",
    "            img1.jpg\n",
    "            img2.jpg\n",
    "        class2/\n",
    "            img1.jpg\n",
    "            ...\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None, mode='contrastive'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: Root directory of dataset\n",
    "            transform: Transform to apply\n",
    "            mode: 'contrastive' or 'supervised'\n",
    "        \"\"\"\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        \n",
    "        # Get all image paths and labels\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        self.classes = []\n",
    "        \n",
    "        # Scan directory structure\n",
    "        for idx, class_dir in enumerate(sorted(self.root_dir.iterdir())):\n",
    "            if class_dir.is_dir():\n",
    "                class_name = class_dir.name\n",
    "                self.classes.append(class_name)\n",
    "                self.class_to_idx[class_name] = idx\n",
    "                \n",
    "                # Get all images in this class\n",
    "                for img_path in class_dir.glob('*'):\n",
    "                    if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                        self.samples.append((str(img_path), idx))\n",
    "        \n",
    "        print(f\"Found {len(self.samples)} images from {len(self.classes)} classes\")\n",
    "        print(f\"Classes: {self.classes}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            if self.mode == 'contrastive':\n",
    "                # Return two views for contrastive learning\n",
    "                view1, view2 = self.transform(image)\n",
    "                return view1, view2, label\n",
    "            else:\n",
    "                # Return single view for supervised learning\n",
    "                image = self.transform(image)\n",
    "                return image, label\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "def create_few_shot_dataset(dataset, k_shot, num_classes):\n",
    "    \"\"\"Create k-shot dataset by sampling k examples per class\"\"\"\n",
    "    class_samples = {i: [] for i in range(num_classes)}\n",
    "    \n",
    "    # Group samples by class\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        class_samples[label].append(idx)\n",
    "    \n",
    "    # Sample k examples per class\n",
    "    few_shot_indices = []\n",
    "    for class_idx in range(num_classes):\n",
    "        indices = class_samples[class_idx]\n",
    "        if len(indices) >= k_shot:\n",
    "            sampled = np.random.choice(indices, k_shot, replace=False)\n",
    "            few_shot_indices.extend(sampled)\n",
    "    \n",
    "    return torch.utils.data.Subset(dataset, few_shot_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"Projection head for contrastive learning (SimCLR)\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=512, hidden_dim=512, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "\n",
    "\n",
    "class ContrastiveEncoder(nn.Module):\n",
    "    \"\"\"Encoder network for contrastive learning\"\"\"\n",
    "    \n",
    "    def __init__(self, base_model='resnet50', projection_dim=128, pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load base encoder (ResNet50)\n",
    "        if base_model == 'resnet50':\n",
    "            resnet = models.resnet50(pretrained=pretrained)\n",
    "            self.embedding_dim = resnet.fc.in_features\n",
    "            self.encoder = nn.Sequential(*list(resnet.children())[:-1])  # Remove FC layer\n",
    "        elif base_model == 'resnet18':\n",
    "            resnet = models.resnet18(pretrained=pretrained)\n",
    "            self.embedding_dim = resnet.fc.in_features\n",
    "            self.encoder = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown base model: {base_model}\")\n",
    "        \n",
    "        # Projection head for contrastive loss\n",
    "        self.projection_head = ProjectionHead(\n",
    "            input_dim=self.embedding_dim,\n",
    "            hidden_dim=self.embedding_dim,\n",
    "            output_dim=projection_dim\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, return_embedding=False):\n",
    "        # Get embedding from encoder\n",
    "        h = self.encoder(x)\n",
    "        h = torch.flatten(h, 1)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return h\n",
    "        \n",
    "        # Project to contrastive space\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        \"\"\"Extract features for downstream tasks\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x, return_embedding=True)\n",
    "\n",
    "\n",
    "class SVMClassifier:\n",
    "    \"\"\"SVM classifier wrapper using sklearn\"\"\"\n",
    "    \n",
    "    def __init__(self, C=1.0, kernel='linear', max_iter=1000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            C: SVM penalty parameter\n",
    "            kernel: 'linear' or 'rbf'\n",
    "            max_iter: Maximum iterations\n",
    "        \"\"\"\n",
    "        if kernel == 'linear':\n",
    "            self.svm = LinearSVC(C=C, max_iter=max_iter, dual=True)\n",
    "        else:\n",
    "            self.svm = SVC(C=C, kernel=kernel, max_iter=max_iter)\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train SVM on features\"\"\"\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.svm.fit(X_scaled, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.svm.predict(X_scaled)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Get accuracy score\"\"\"\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.svm.score(X_scaled, y)\n",
    "\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    \"\"\"Linear probe for comparison baseline\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class SoftmaxClassifier(nn.Module):\n",
    "    \"\"\"Softmax classifier head for fine-tuning\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, num_classes, freeze_encoder=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.fc = nn.Linear(encoder.embedding_dim, num_classes)\n",
    "        \n",
    "        if freeze_encoder:\n",
    "            for param in self.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.encoder.get_embedding(x)\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Contrastive Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    \"\"\"Normalized Temperature-scaled Cross Entropy Loss (NT-Xent)\n",
    "    \n",
    "    This is the contrastive loss used in SimCLR\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def forward(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z_i: Projections from view 1, shape [batch_size, projection_dim]\n",
    "            z_j: Projections from view 2, shape [batch_size, projection_dim]\n",
    "        \n",
    "        Returns:\n",
    "            loss: NT-Xent loss\n",
    "        \"\"\"\n",
    "        batch_size = z_i.shape[0]\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        z_i = F.normalize(z_i, dim=1)\n",
    "        z_j = F.normalize(z_j, dim=1)\n",
    "        \n",
    "        # Concatenate views\n",
    "        representations = torch.cat([z_i, z_j], dim=0)  # [2*batch_size, projection_dim]\n",
    "        \n",
    "        # Compute similarity matrix\n",
    "        similarity_matrix = F.cosine_similarity(\n",
    "            representations.unsqueeze(1), \n",
    "            representations.unsqueeze(0), \n",
    "            dim=2\n",
    "        )  # [2*batch_size, 2*batch_size]\n",
    "        \n",
    "        # Create mask to remove self-similarity\n",
    "        mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z_i.device)\n",
    "        similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)\n",
    "        \n",
    "        # Compute positive pairs\n",
    "        positives = torch.cat([\n",
    "            torch.diag(similarity_matrix, batch_size),\n",
    "            torch.diag(similarity_matrix, -batch_size)\n",
    "        ], dim=0).reshape(2 * batch_size, 1)\n",
    "        \n",
    "        # Compute negatives (all other pairs)\n",
    "        negatives = similarity_matrix[~mask].reshape(2 * batch_size, -1)\n",
    "        \n",
    "        # Concatenate and scale by temperature\n",
    "        logits = torch.cat([positives, negatives], dim=1) / self.temperature\n",
    "        \n",
    "        # Labels are always 0 (first column = positive pair)\n",
    "        labels = torch.zeros(2 * batch_size, dtype=torch.long, device=z_i.device)\n",
    "        \n",
    "        # Cross entropy loss\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_contrastive_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"Train one epoch of contrastive learning\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for view1, view2, _ in pbar:\n",
    "        view1, view2 = view1.to(device), view2.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        z1 = model(view1)\n",
    "        z2 = model(view2)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(z1, z2)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def train_contrastive(model, train_loader, config, device):\n",
    "    \"\"\"Full contrastive pretraining\"\"\"\n",
    "    criterion = NTXentLoss(temperature=config.TEMPERATURE).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config.CONTRASTIVE_LR,\n",
    "        weight_decay=config.CONTRASTIVE_WEIGHT_DECAY\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=config.CONTRASTIVE_EPOCHS\n",
    "    )\n",
    "    \n",
    "    history = {'loss': []}\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config.CONTRASTIVE_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.CONTRASTIVE_EPOCHS}\")\n",
    "        \n",
    "        # Train\n",
    "        loss = train_contrastive_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        history['loss'].append(loss)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Average Loss: {loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, os.path.join(config.CHECKPOINT_DIR, 'best_contrastive.pth'))\n",
    "            print(\"✓ Saved best model\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    \"\"\"Extract features from pretrained encoder\"\"\"\n",
    "    model.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Extracting features'):\n",
    "            images = images.to(device)\n",
    "            features = model.get_embedding(images)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "            labels_list.append(labels.numpy())\n",
    "    \n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def train_svm_classifier(encoder, train_loader, test_loader, config, device):\n",
    "    \"\"\"Train SVM on frozen features\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training SVM Classifier\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting training features...\")\n",
    "    X_train, y_train = extract_features(encoder, train_loader, device)\n",
    "    \n",
    "    print(\"Extracting test features...\")\n",
    "    X_test, y_test = extract_features(encoder, test_loader, device)\n",
    "    \n",
    "    print(f\"Train features shape: {X_train.shape}\")\n",
    "    print(f\"Test features shape: {X_test.shape}\")\n",
    "    \n",
    "    # Train SVM\n",
    "    print(f\"\\nTraining SVM (C={config.SVM_C}, kernel={config.SVM_KERNEL})...\")\n",
    "    svm = SVMClassifier(C=config.SVM_C, kernel=config.SVM_KERNEL, max_iter=config.SVM_MAX_ITER)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_acc = svm.score(X_train, y_train)\n",
    "    test_acc = svm.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Train Accuracy: {train_acc*100:.2f}%\")\n",
    "    print(f\"  Test Accuracy: {test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Get predictions for detailed metrics\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    return svm, test_acc, y_pred, y_test\n",
    "\n",
    "\n",
    "def train_linear_probe(encoder, train_loader, test_loader, num_classes, config, device):\n",
    "    \"\"\"Train linear probe baseline\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training Linear Probe\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create linear probe\n",
    "    probe = LinearProbe(encoder.embedding_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(probe.parameters(), lr=config.FINETUNE_LR)\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(config.FINETUNE_EPOCHS):\n",
    "        probe.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Get frozen features\n",
    "            with torch.no_grad():\n",
    "                features = encoder.get_embedding(images)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = probe(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Evaluate\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            probe.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    features = encoder.get_embedding(images)\n",
    "                    outputs = probe(features)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            acc = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{config.FINETUNE_EPOCHS}, Loss: {total_loss/len(train_loader):.4f}, Test Acc: {acc:.2f}%\")\n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "    \n",
    "    return best_acc\n",
    "\n",
    "\n",
    "def train_softmax_finetune(encoder, train_loader, test_loader, num_classes, config, device):\n",
    "    \"\"\"Fine-tune with softmax classifier\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Fine-tuning with Softmax\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    model = SoftmaxClassifier(encoder, num_classes, freeze_encoder=False).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.FINETUNE_LR, weight_decay=config.FINETUNE_WEIGHT_DECAY)\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(config.FINETUNE_EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Evaluate\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in test_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            acc = 100 * correct / total\n",
    "            print(f\"Epoch {epoch+1}/{config.FINETUNE_EPOCHS}, Loss: {total_loss/len(train_loader):.4f}, Test Acc: {acc:.2f}%\")\n",
    "            \n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title='Confusion Matrix'):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "def plot_tsne(features, labels, classes, title='t-SNE Visualization'):\n",
    "    \"\"\"Plot t-SNE visualization of features\"\"\"\n",
    "    print(\"Computing t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    features_2d = tsne.fit_transform(features)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], \n",
    "                         c=labels, cmap='tab10', alpha=0.6, s=20)\n",
    "    plt.colorbar(scatter, ticks=range(len(classes)))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('t-SNE 1')\n",
    "    plt.ylabel('t-SNE 2')\n",
    "    \n",
    "    # Add legend\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                         markerfacecolor=plt.cm.tab10(i/len(classes)), \n",
    "                         markersize=8, label=classes[i]) \n",
    "              for i in range(len(classes))]\n",
    "    plt.legend(handles=handles, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training loss curve\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['loss'])\n",
    "    plt.title('Contrastive Learning - Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "\n",
    "def evaluate_few_shot(encoder, full_dataset, k_shots, num_classes, config, device):\n",
    "    \"\"\"Evaluate few-shot learning performance\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Create supervised augmentation dataset\n",
    "    full_dataset_sup = PlantWildV2Dataset(\n",
    "        root_dir=config.DATA_ROOT,\n",
    "        transform=StandardAugmentation(config.IMG_SIZE, is_train=False),\n",
    "        mode='supervised'\n",
    "    )\n",
    "    \n",
    "    # Create test set (use 30% for testing)\n",
    "    test_size = int(0.3 * len(full_dataset_sup))\n",
    "    train_size = len(full_dataset_sup) - test_size\n",
    "    _, test_dataset = random_split(full_dataset_sup, [train_size, test_size])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    for k in k_shots:\n",
    "        print(f\"\\n{k}-shot learning...\")\n",
    "        \n",
    "        # Create k-shot dataset\n",
    "        few_shot_dataset = create_few_shot_dataset(full_dataset_sup, k, num_classes)\n",
    "        few_shot_loader = DataLoader(few_shot_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        # Train SVM on k-shot data\n",
    "        svm, test_acc, _, _ = train_svm_classifier(\n",
    "            encoder, few_shot_loader, test_loader, config, device\n",
    "        )\n",
    "        \n",
    "        results[f'{k}-shot'] = test_acc * 100\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_classification_report(y_true, y_pred, classes):\n",
    "    \"\"\"Print detailed classification report\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Classification Report\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Main Experiment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_experiment(config):\n",
    "    \"\"\"Run complete experimental pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"CONTRASTIVE LEARNING + SVM FOR PLANT DISEASE DETECTION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Load dataset\n",
    "    print(\"\\n[1/6] Loading PlantWildV2 Dataset...\")\n",
    "    \n",
    "    # Contrastive dataset\n",
    "    contrastive_dataset = PlantWildV2Dataset(\n",
    "        root_dir=config.DATA_ROOT,\n",
    "        transform=ContrastiveAugmentation(config.IMG_SIZE, config.COLOR_JITTER_STRENGTH),\n",
    "        mode='contrastive'\n",
    "    )\n",
    "    \n",
    "    # Supervised dataset\n",
    "    supervised_dataset = PlantWildV2Dataset(\n",
    "        root_dir=config.DATA_ROOT,\n",
    "        transform=StandardAugmentation(config.IMG_SIZE, is_train=True),\n",
    "        mode='supervised'\n",
    "    )\n",
    "    \n",
    "    supervised_dataset_test = PlantWildV2Dataset(\n",
    "        root_dir=config.DATA_ROOT,\n",
    "        transform=StandardAugmentation(config.IMG_SIZE, is_train=False),\n",
    "        mode='supervised'\n",
    "    )\n",
    "    \n",
    "    num_classes = len(contrastive_dataset.classes)\n",
    "    classes = contrastive_dataset.classes\n",
    "    \n",
    "    # Split datasets\n",
    "    train_size = int(0.7 * len(supervised_dataset))\n",
    "    val_size = len(supervised_dataset) - train_size\n",
    "    train_dataset, _ = random_split(supervised_dataset, [train_size, val_size])\n",
    "    _, test_dataset = random_split(supervised_dataset_test, [train_size, val_size])\n",
    "    \n",
    "    # Create dataloaders\n",
    "    contrastive_loader = DataLoader(\n",
    "        contrastive_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS\n",
    "    )\n",
    "    \n",
    "    print(f\"  ✓ Found {num_classes} classes\")\n",
    "    print(f\"  ✓ Train size: {len(train_dataset)}\")\n",
    "    print(f\"  ✓ Test size: {len(test_dataset)}\")\n",
    "    \n",
    "    # 2. Contrastive Pretraining\n",
    "    print(\"\\n[2/6] Contrastive Pretraining...\")\n",
    "    encoder = ContrastiveEncoder(\n",
    "        base_model='resnet50',\n",
    "        projection_dim=config.PROJECTION_DIM,\n",
    "        pretrained=True\n",
    "    ).to(device)\n",
    "    \n",
    "    history = train_contrastive(encoder, contrastive_loader, config, device)\n",
    "    \n",
    "    # Plot training history\n",
    "    fig = plot_training_history(history)\n",
    "    fig.savefig(os.path.join(config.RESULTS_DIR, 'training_loss.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Extract and visualize features\n",
    "    print(\"\\n[3/6] Extracting Features...\")\n",
    "    X_train, y_train = extract_features(encoder, train_loader, device)\n",
    "    X_test, y_test = extract_features(encoder, test_loader, device)\n",
    "    \n",
    "    # t-SNE visualization\n",
    "    print(\"Creating t-SNE visualization...\")\n",
    "    sample_size = min(2000, len(X_test))\n",
    "    sample_indices = np.random.choice(len(X_test), sample_size, replace=False)\n",
    "    fig = plot_tsne(X_test[sample_indices], y_test[sample_indices], classes)\n",
    "    fig.savefig(os.path.join(config.RESULTS_DIR, 'tsne_features.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Train SVM Classifier\n",
    "    print(\"\\n[4/6] Training SVM Classifier...\")\n",
    "    svm, svm_acc, y_pred_svm, y_test_svm = train_svm_classifier(\n",
    "        encoder, train_loader, test_loader, config, device\n",
    "    )\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print_classification_report(y_test_svm, y_pred_svm, classes)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    fig = plot_confusion_matrix(y_test_svm, y_pred_svm, classes, 'SVM Confusion Matrix')\n",
    "    fig.savefig(os.path.join(config.RESULTS_DIR, 'confusion_matrix_svm.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Baseline Comparisons\n",
    "    print(\"\\n[5/6] Training Baseline Methods...\")\n",
    "    \n",
    "    # Linear probe\n",
    "    linear_acc = train_linear_probe(\n",
    "        encoder, train_loader, test_loader, num_classes, config, device\n",
    "    )\n",
    "    \n",
    "    # Softmax fine-tuning\n",
    "    softmax_acc = train_softmax_finetune(\n",
    "        encoder, train_loader, test_loader, num_classes, config, device\n",
    "    )\n",
    "    \n",
    "    # 6. Few-shot Learning\n",
    "    few_shot_results = {}\n",
    "    if config.ENABLE_FEW_SHOT:\n",
    "        print(\"\\n[6/6] Few-shot Learning Evaluation...\")\n",
    "        few_shot_results = evaluate_few_shot(\n",
    "            encoder, supervised_dataset_test, config.FEW_SHOT_K, \n",
    "            num_classes, config, device\n",
    "        )\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"FINAL RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nFull Dataset Results:\")\n",
    "    print(f\"  SVM Classifier:          {svm_acc*100:.2f}%\")\n",
    "    print(f\"  Linear Probe:            {linear_acc:.2f}%\")\n",
    "    print(f\"  Softmax Fine-tuning:     {softmax_acc:.2f}%\")\n",
    "    \n",
    "    if few_shot_results:\n",
    "        print(f\"\\nFew-shot Learning Results:\")\n",
    "        for k, acc in few_shot_results.items():\n",
    "            print(f\"  {k}: {acc:.2f}%\")\n",
    "    \n",
    "    # Save results\n",
    "    results_dict = {\n",
    "        'svm_accuracy': float(svm_acc * 100),\n",
    "        'linear_probe_accuracy': float(linear_acc),\n",
    "        'softmax_accuracy': float(softmax_acc),\n",
    "        'few_shot_results': few_shot_results,\n",
    "        'num_classes': num_classes,\n",
    "        'classes': classes\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(os.path.join(config.RESULTS_DIR, 'results.json'), 'w') as f:\n",
    "        json.dump(results_dict, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n✓ Results saved to {config.RESULTS_DIR}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results_dict, encoder, svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update config with your dataset path\n",
    "config.DATA_ROOT = './plantwildV2'  # Change this to your actual path\n",
    "\n",
    "# Run full experiment\n",
    "results, trained_encoder, trained_svm = run_full_experiment(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Inference and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, encoder, svm, config, classes):\n",
    "    \"\"\"Predict disease for a single image\"\"\"\n",
    "    # Load and preprocess image\n",
    "    transform = StandardAugmentation(config.IMG_SIZE, is_train=False)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    with torch.no_grad():\n",
    "        features = encoder.get_embedding(image_tensor)\n",
    "        features = features.cpu().numpy()\n",
    "    \n",
    "    # Predict\n",
    "    prediction = svm.predict(features)[0]\n",
    "    predicted_class = classes[prediction]\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Predicted: {predicted_class}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "# image_path = 'path/to/test/image.jpg'\n",
    "# prediction = predict_image(image_path, trained_encoder, trained_svm, config, results['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_methods_plot(results):\n",
    "    \"\"\"Create comparison bar plot of different methods\"\"\"\n",
    "    methods = ['SVM', 'Linear Probe', 'Softmax Fine-tune']\n",
    "    accuracies = [\n",
    "        results['svm_accuracy'],\n",
    "        results['linear_probe_accuracy'],\n",
    "        results['softmax_accuracy']\n",
    "    ]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(methods, accuracies, color=['#2ecc71', '#3498db', '#e74c3c'])\n",
    "    plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "    plt.title('Comparison of Classification Methods', fontsize=14, fontweight='bold')\n",
    "    plt.ylim([0, 100])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{acc:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()\n",
    "\n",
    "# Plot comparison\n",
    "if 'results' in locals():\n",
    "    fig = compare_methods_plot(results)\n",
    "    fig.savefig(os.path.join(config.RESULTS_DIR, 'methods_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model_for_deployment(encoder, svm, config, classes):\n",
    "    \"\"\"Save models for production deployment\"\"\"\n",
    "    \n",
    "    # Save encoder\n",
    "    torch.save({\n",
    "        'model_state_dict': encoder.state_dict(),\n",
    "        'embedding_dim': encoder.embedding_dim,\n",
    "        'classes': classes\n",
    "    }, os.path.join(config.CHECKPOINT_DIR, 'encoder_final.pth'))\n",
    "    \n",
    "    # Save SVM\n",
    "    with open(os.path.join(config.CHECKPOINT_DIR, 'svm_final.pkl'), 'wb') as f:\n",
    "        pickle.dump(svm, f)\n",
    "    \n",
    "    # Save config\n",
    "    config_dict = {\n",
    "        'IMG_SIZE': config.IMG_SIZE,\n",
    "        'EMBEDDING_DIM': config.EMBEDDING_DIM,\n",
    "        'classes': classes\n",
    "    }\n",
    "    with open(os.path.join(config.CHECKPOINT_DIR, 'config.json'), 'w') as f:\n",
    "        json.dump(config_dict, f, indent=4)\n",
    "    \n",
    "    print(f\"✓ Models saved to {config.CHECKPOINT_DIR}\")\n",
    "\n",
    "# Save models\n",
    "if 'trained_encoder' in locals() and 'trained_svm' in locals():\n",
    "    save_model_for_deployment(trained_encoder, trained_svm, config, results['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Citation and References\n",
    "\n",
    "If you use this code in your research, please cite:\n",
    "\n",
    "```bibtex\n",
    "@article{yourname2025contrastive,\n",
    "  title={Margin-Aware Contrastive Learning with SVM for Plant Disease Detection},\n",
    "  author={Your Name},\n",
    "  journal={arXiv preprint arXiv:XXXX.XXXXX},\n",
    "  year={2025}\n",
    "}\n",
    "```\n",
    "\n",
    "### References\n",
    "1. Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations. ICML.\n",
    "2. Tang, Y. (2013). Deep Learning using Linear Support Vector Machines. arXiv:1306.0239.\n",
    "3. Agarap, A. F. (2017). An Architecture Combining Convolutional Neural Network (CNN) and Support Vector Machine (SVM) for Image Classification. arXiv:1712.03541."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
